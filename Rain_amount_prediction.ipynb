{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:01.871985Z","iopub.status.busy":"2022-11-22T20:13:01.871575Z","iopub.status.idle":"2022-11-22T20:13:01.879029Z","shell.execute_reply":"2022-11-22T20:13:01.877987Z","shell.execute_reply.started":"2022-11-22T20:13:01.871954Z"},"trusted":true},"outputs":[],"source":["from category_encoders import TargetEncoder\n","import math\n","from sklearn.preprocessing import Normalizer,normalize\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","# target = 'Rainfall', RainTomorrow'\n","encoder1 = TargetEncoder()\n","encoder2 = TargetEncoder()\n","encoder3 = TargetEncoder()\n","encoder4 = TargetEncoder()\n","\n","# trainColumns = list(set(train.columns)-set(['Rainfall', 'RainTomorrow']))\n","nor = Normalizer()\n","target = MinMaxScaler()\n","\n","def transform(x):\n","   return  np.exp(-x/2)# np.exp(-(x-mean)/variance)#np.exp(-x/2) #np.exp(-x/2)\n","def inverse(x):\n","   return -2*np.log(x)# -variance* np.log(x)+mean #-2*np.log(x) #-2*np.log(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:02.101250Z","iopub.status.busy":"2022-11-22T20:13:02.100902Z","iopub.status.idle":"2022-11-22T20:13:02.108112Z","shell.execute_reply":"2022-11-22T20:13:02.107165Z","shell.execute_reply.started":"2022-11-22T20:13:02.101219Z"},"trusted":true},"outputs":[],"source":["def convert_date(data):\n","    #There don't seem to be any error in dates so parsing values into datetime\n","    data['Date']= pd.to_datetime(data[\"Date\"])\n","    #Creating a collumn of year\n","    data['year'] = 2022-data.Date.dt.year\n","\n","    # function to encode datetime into cyclic parameters. \n","    #As I am planning to use this data in a neural network I prefer the months and days in a cyclic continuous feature. \n","\n","    def encode(data, col, max_val):\n","        data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n","        data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n","        return data\n","\n","    data['month'] = data.Date.dt.month\n","    data = encode(data, 'month', 12)\n","\n","    data['day'] = data.Date.dt.day\n","    data = encode(data, 'day', 31)\n","\n","#     data.head()\n","    return data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:02.344446Z","iopub.status.busy":"2022-11-22T20:13:02.343783Z","iopub.status.idle":"2022-11-22T20:13:02.355881Z","shell.execute_reply":"2022-11-22T20:13:02.354823Z","shell.execute_reply.started":"2022-11-22T20:13:02.344415Z"},"trusted":true},"outputs":[],"source":["def prepare_train(train):\n","    train.drop(columns=['Unnamed: 0'],inplace = True)\n","    train['RainTomorrow'] = np.where(train[\"RainTomorrow\"] == \"Yes\", 1, 0)\n","    train['RainTomorrow'] = train['RainTomorrow'].astype(np.int8)\n","        \n","    train[[\"year\", \"month\", \"day\"]] = train[\"Date\"].str.split(\"-\", expand = True)\n","    train.drop(inplace = True,columns=['Date'])\n","\n","    train['day'] = train['day'].astype(np.int16)\n","    train['month'] = train['month'].astype(np.int16)\n","    train['year'] = 2022 - train['year'].astype(np.int16)\n","#     train = convert_date(train)\n","#     train.drop(inplace = True,columns=['Date'])\n","    \n","    train['Location'] = encoder1.fit_transform(train['Location'], train[['Rainfall']])\n","    train['WindDir9am'] = encoder2.fit_transform(train['WindDir9am'], train[['Rainfall']])\n","    train['WindDir3pm'] = encoder3.fit_transform(train['WindDir3pm'], train[['Rainfall']])\n","    train['WindGustDir'] = encoder4.fit_transform(train['WindGustDir'], train[['Rainfall']])\n","    \n","    train['min_max_temp_avg'] = train[['MinTemp','MaxTemp']].mean(axis=1)\n","    train['pressure_3_9_avg'] = train[['Pressure9am','Pressure3pm']].mean(axis=1)\n","    train['temp_3_9_avg'] = train[['Temp9am','Temp3pm']].mean(axis=1)\n","   \n","    train.drop(columns=['MinTemp','MaxTemp','Pressure9am','Pressure3pm','Temp9am','Temp3pm'],inplace = True)\n","    trainColumns = list(set(train.columns)-set(['Rainfall', 'RainTomorrow']))\n","#     'year','month','day'\n","    train[trainColumns] = nor.fit_transform(train[trainColumns])\n","#     train['Rainfall'] = (train['Rainfall']-2.9) **(1/3)\n","    train['Rainfall'] = train['Rainfall'].apply(transform)\n","    train['Rainfall'] = target.fit_transform(train[['Rainfall']])\n","    return train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:02.584396Z","iopub.status.busy":"2022-11-22T20:13:02.584060Z","iopub.status.idle":"2022-11-22T20:13:02.597670Z","shell.execute_reply":"2022-11-22T20:13:02.596550Z","shell.execute_reply.started":"2022-11-22T20:13:02.584366Z"},"trusted":true},"outputs":[],"source":["def prepare_validation(train):\n","    train.drop(columns=['Unnamed: 0'],inplace = True)\n","    train['RainTomorrow'] = np.where(train[\"RainTomorrow\"] == \"Yes\", 1, 0)\n","    train['RainTomorrow'] = train['RainTomorrow'].astype(np.int8)\n","        \n","    train[[\"year\", \"month\", \"day\"]] = train[\"Date\"].str.split(\"-\", expand = True)\n","    train.drop(inplace = True,columns=['Date'])\n","\n","    train['day'] = train['day'].astype(np.int16)\n","    train['month'] = train['month'].astype(np.int16)\n","    train['year'] = 2022 - train['year'].astype(np.int16)\n","    ## create new features based on date\n","#     train = convert_date(train)\n","#     train.drop(inplace = True,columns=['Date'])\n","    \n","    train['Location'] = encoder1.transform(train['Location'])\n","    train['WindDir9am'] = encoder2.transform(train['WindDir9am'])\n","    train['WindDir3pm'] = encoder3.transform(train['WindDir3pm'])\n","    train['WindGustDir'] = encoder4.transform(train['WindGustDir'])\n","    \n","    train['min_max_temp_avg'] = train[['MinTemp','MaxTemp']].mean(axis=1)\n","    train['pressure_3_9_avg'] = train[['Pressure9am','Pressure3pm']].mean(axis=1)\n","    train['temp_3_9_avg'] = train[['Temp9am','Temp3pm']].mean(axis=1)\n","   \n","    train.drop(columns=['MinTemp','MaxTemp','Pressure9am','Pressure3pm','Temp9am','Temp3pm'],inplace = True)\n","    trainColumns = list(set(train.columns)-set(['Rainfall', 'RainTomorrow']))\n","#     'year','month','day'\n","    train[trainColumns] = nor.transform(train[trainColumns])\n","#     train['Rainfall'] = (train['Rainfall']-2.9) **(1/3)\n","    train['Rainfall'] = train['Rainfall'].apply(transform)\n","    train['Rainfall'] = target.transform(train[['Rainfall']])\n","    return train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:02.941608Z","iopub.status.busy":"2022-11-22T20:13:02.941234Z","iopub.status.idle":"2022-11-22T20:13:02.953016Z","shell.execute_reply":"2022-11-22T20:13:02.951748Z","shell.execute_reply.started":"2022-11-22T20:13:02.941579Z"},"trusted":true},"outputs":[],"source":["def prepare_test(test):\n","    test.drop(columns=['Unnamed: 0'],inplace = True)\n","    \n","    test[[\"year\", \"month\", \"day\"]] = test[\"Date\"].str.split(\"-\", expand = True)\n","    test.drop(inplace = True,columns=['Date'])\n","\n","    test['day'] = test['day'].astype(np.int16)\n","    test['month'] = test['month'].astype(np.int16)\n","    test['year'] = 2022 - test['year'].astype(np.int16)\n","#     test = convert_date(test)\n","#     test.drop(inplace = True,columns=['Date'])\n","    \n","    test['Location'] = encoder1.transform(test['Location'])\n","    test['WindDir9am'] = encoder2.transform(test['WindDir9am'])\n","    test['WindDir3pm'] = encoder3.transform(test['WindDir3pm'])\n","    test['WindGustDir'] = encoder4.transform(test['WindGustDir'])\n","        \n","    test['min_max_temp_avg'] = test[['MinTemp','MaxTemp']].mean(axis=1)\n","    test['pressure_3_9_avg'] = test[['Pressure9am','Pressure3pm']].mean(axis=1)\n","    test['temp_3_9_avg'] = test[['Temp9am','Temp3pm']].mean(axis=1)\n","\n","    test.drop(columns=['MinTemp','MaxTemp','Pressure9am','Pressure3pm','Temp9am','Temp3pm'],inplace = True)\n","    test = pd.DataFrame(nor.transform(test),columns=list(test.columns),index=None)\n","    return test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:03.221219Z","iopub.status.busy":"2022-11-22T20:13:03.220881Z","iopub.status.idle":"2022-11-22T20:13:03.745355Z","shell.execute_reply":"2022-11-22T20:13:03.744240Z","shell.execute_reply.started":"2022-11-22T20:13:03.221189Z"},"trusted":true},"outputs":[],"source":["from  sklearn.model_selection import train_test_split\n","\n","train,validation = train_test_split(pd.read_csv('/kaggle/input/tah-rain-predection/train.csv'),test_size=0.2)\n","validation.to_csv('validation.csv',index=None)\n","train.to_csv('train.csv',index=None)\n","validation_size = len(validation)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:04.741520Z","iopub.status.busy":"2022-11-22T20:13:04.741124Z","iopub.status.idle":"2022-11-22T20:13:05.136966Z","shell.execute_reply":"2022-11-22T20:13:05.136061Z","shell.execute_reply.started":"2022-11-22T20:13:04.741489Z"},"trusted":true},"outputs":[],"source":["# # # import matplotlib.pyplot as plt\n","from scipy import stats\n","\n","t = pd.read_csv('/kaggle/input/tah-rain-predection/train.csv')\n","t['Rainfall'] = t['Rainfall'].apply(transform)\n","t['Rainfall'].hist()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:13.347883Z","iopub.status.busy":"2022-11-22T20:13:13.347494Z","iopub.status.idle":"2022-11-22T20:13:13.356912Z","shell.execute_reply":"2022-11-22T20:13:13.355748Z","shell.execute_reply.started":"2022-11-22T20:13:13.347851Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","class MyDataset_Train(Dataset):\n"," \n","  def __init__(self,file):\n","    train = pd.read_csv(file)\n","    train = prepare_train(train)\n","    y1 = train['Rainfall'].values\n","    y2 = train['RainTomorrow'].values\n","    x = train.drop(columns=['Rainfall', 'RainTomorrow']).values\n","    \n","    self.x_train=torch.tensor(x,dtype=torch.float32)\n","    self.y1_train=torch.tensor(np.expand_dims(y1, axis=1),dtype=torch.float32)\n","    self.y2_train=torch.tensor(np.expand_dims(y2, axis=1),dtype=torch.float32)\n"," \n","  def __len__(self):\n","    return len(self.y1_train)\n","   \n","  def __getitem__(self,idx):\n","    return self.x_train[idx],self.y1_train[idx],self.y2_train[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:13.791411Z","iopub.status.busy":"2022-11-22T20:13:13.791041Z","iopub.status.idle":"2022-11-22T20:13:13.801145Z","shell.execute_reply":"2022-11-22T20:13:13.799862Z","shell.execute_reply.started":"2022-11-22T20:13:13.791373Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","class MyDataset_validation(Dataset):\n"," \n","  def __init__(self,file):\n","    train = pd.read_csv(file)\n","    train = prepare_validation(train)\n","    y1 = train['Rainfall'].values\n","    y2 = train['RainTomorrow'].values\n","    x = train.drop(columns=['Rainfall', 'RainTomorrow']).values\n","    \n","    self.x_train=torch.tensor(x,dtype=torch.float32)\n","    self.y1_train=torch.tensor(np.expand_dims(y1, axis=1),dtype=torch.float32)\n","    self.y2_train=torch.tensor(np.expand_dims(y2, axis=1),dtype=torch.float32)\n"," \n","  def __len__(self):\n","    return len(self.y1_train)\n","   \n","  def __getitem__(self,idx):\n","    return self.x_train[idx],self.y1_train[idx],self.y2_train[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:13:14.302084Z","iopub.status.busy":"2022-11-22T20:13:14.300773Z","iopub.status.idle":"2022-11-22T20:13:14.309129Z","shell.execute_reply":"2022-11-22T20:13:14.307747Z","shell.execute_reply.started":"2022-11-22T20:13:14.302036Z"},"trusted":true},"outputs":[],"source":["class MyDataset_Test(Dataset):\n"," \n","  def __init__(self,file):\n","    test = pd.read_csv(file)\n","    x = prepare_test(test).values\n","    \n","    self.x_train=torch.tensor(x,dtype=torch.float32)\n"," \n","  def __len__(self):\n","    return len(self.x_train)\n","   \n","  def __getitem__(self,idx):\n","    return self.x_train[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T20:31:46.780719Z","iopub.status.busy":"2022-11-22T20:31:46.780345Z","iopub.status.idle":"2022-11-22T20:31:47.511717Z","shell.execute_reply":"2022-11-22T20:31:47.510488Z","shell.execute_reply.started":"2022-11-22T20:31:46.780687Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets\n","from torch.utils.data import Dataset, DataLoader\n","\n","# /kaggle/input/tah-rain-predection/train.csv\n","# /kaggle/input/tah-rain-predection/test.csv\n","train = MyDataset_Train('train.csv')#'/kaggle/input/tah-rain-predection/train.csv') \n","train_loader=DataLoader(train,batch_size=10,shuffle=True) #batch_size=10\n","validation = MyDataset_validation('validation.csv')\n","validation_loader=DataLoader(validation,batch_size=10,shuffle=True)\n","test = MyDataset_Test('/kaggle/input/tah-rain-predection/test.csv') \n","test_loader=DataLoader(test,batch_size=len(test),shuffle=False)\n","\n","num_feature = len(next(iter(train))[0])\n","class LinearRegression(torch.nn.Module):\n","\n","    def __init__(self): \n","          super(LinearRegression, self).__init__() \n","          self.linear1 = torch.nn.Linear(num_feature, 256)\n","          self.relu1 = torch.nn.ReLU()\n","          self.linear2 = torch.nn.Linear(256, 256)\n","          self.relu2 = torch.nn.ReLU()\n","#           self.dropout = torch.nn.Dropout(0.3)\n","          self.linear3 = torch.nn.Linear(256, 1)\n","          self.relu3 = torch.nn.ReLU()\n","          self.linear4 = torch.nn.Linear(256, 1)\n","      \n","    def forward(self, x): \n","               out = self.linear1(x)\n","               out = self.relu1(out)\n","               out = self.linear2(out)\n","               out = self.relu2(out)\n","               #out = self.dropout(out)\n","               predict_y1 = self.linear3(out) #abs(self.linear3(out)) \n","               predict_y1 = self.relu3(predict_y1)\n","               predict_y2 = self.linear4(out)\n","               return predict_y1 ,predict_y2\n","linear_model = LinearRegression().to('cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":false,"execution":{"iopub.execute_input":"2022-11-22T21:41:59.071053Z","iopub.status.busy":"2022-11-22T21:41:59.070588Z","iopub.status.idle":"2022-11-22T21:42:17.649603Z","shell.execute_reply":"2022-11-22T21:42:17.648501Z","shell.execute_reply.started":"2022-11-22T21:41:59.071013Z"},"trusted":true},"outputs":[],"source":["# linear_model = LinearRegression().to('cpu')\n","linear_model.train()\n","define_criterion1 = torch.nn.MSELoss()#size_average=False)\n","define_criterion2 = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([38947/11053]))\n","SGD_optimizer = torch.optim.Adam(linear_model.parameters(), lr=0.000001)#0.0001)\n","batch_size = 10\n","for epoch in range(2): \n","    loss = 0\n","    \n","    for feature, label1,label2 in train_loader:\n","        SGD_optimizer.zero_grad() \n","        predict_y1, predict_y2= linear_model(feature) \n","        loss1 = define_criterion1(predict_y1, label1)\n","        loss2 = define_criterion2(predict_y2, label2)\n","        loss = loss1 + loss2\n","        loss.backward() \n","        SGD_optimizer.step() \n","    print('epoch {}, loss function {}'.format(epoch, loss.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T21:42:20.110043Z","iopub.status.busy":"2022-11-22T21:42:20.109330Z","iopub.status.idle":"2022-11-22T21:42:20.150294Z","shell.execute_reply":"2022-11-22T21:42:20.149392Z","shell.execute_reply.started":"2022-11-22T21:42:20.110007Z"},"trusted":true},"outputs":[],"source":["linear_model.eval() \n","# pred1,pred2=[],[]\n","for inp in test_loader:\n","    predict_y1,predict_y2 = linear_model(inp)\n","predict_y2 = np.where(predict_y2 >=0.5, 1, 0)\n","predict_y2 = predict_y2.reshape((6469))\n","predict_y1 = target.inverse_transform(predict_y1.detach().numpy()).reshape((6469))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T21:42:20.698910Z","iopub.status.busy":"2022-11-22T21:42:20.698025Z","iopub.status.idle":"2022-11-22T21:42:20.763627Z","shell.execute_reply":"2022-11-22T21:42:20.762648Z","shell.execute_reply.started":"2022-11-22T21:42:20.698863Z"},"trusted":true},"outputs":[],"source":["sub = pd.read_csv('/kaggle/input/tah-rain-predection/sample.csv')\n","sub['Rainfall'] = predict_y1\n","sub['RainTomorrow'] = predict_y2\n","sub['Rainfall'] = target.inverse_transform(sub[['Rainfall']])\n","sub['Rainfall'] = abs(sub['Rainfall'].apply(inverse))\n","l= sub['Rainfall']==np.inf\n","count =0\n","for i in range(len(l)) :\n","    if(l[i]):\n","        count+=1\n","        sub.loc[i,'Rainfall']=0\n","count,len(sub['Rainfall'])\n","sub.to_csv(\"result.csv\",index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T21:42:21.969450Z","iopub.status.busy":"2022-11-22T21:42:21.969089Z","iopub.status.idle":"2022-11-22T21:42:21.981766Z","shell.execute_reply":"2022-11-22T21:42:21.980321Z","shell.execute_reply.started":"2022-11-22T21:42:21.969419Z"},"trusted":true},"outputs":[],"source":["sub[['RainTomorrow']].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T21:42:24.981585Z","iopub.status.busy":"2022-11-22T21:42:24.981015Z","iopub.status.idle":"2022-11-22T21:42:25.012364Z","shell.execute_reply":"2022-11-22T21:42:25.010926Z","shell.execute_reply.started":"2022-11-22T21:42:24.981531Z"},"trusted":true},"outputs":[],"source":["sub[['Rainfall']]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T21:42:34.052713Z","iopub.status.busy":"2022-11-22T21:42:34.052365Z","iopub.status.idle":"2022-11-22T21:42:37.217904Z","shell.execute_reply":"2022-11-22T21:42:37.216864Z","shell.execute_reply.started":"2022-11-22T21:42:34.052682Z"},"trusted":true},"outputs":[],"source":["loss = 0\n","prediction = 0\n","loss_classification =0\n","count_1=0\n","count_0 = 0\n","count_validation = 0\n","for inp,label1,label2 in validation:\n","    predict_y1,predict_y2 = linear_model(inp)\n","    for predLabel,trueLabel in zip(predict_y1,label1):\n","        loss += (predLabel-trueLabel)**2\n","    pred = np.where(predict_y2 >=0.5, 1.0, 0.0).reshape((len(label2)))\n","    label = label2.detach().numpy().reshape((len(label2)))\n","    for predLabel,trueLabel in zip(pred,label):\n","        if(predLabel==trueLabel):\n","            prediction+=1\n","        if(predLabel==trueLabel==1):\n","            count_1+=1\n","        if(predLabel==trueLabel==0):\n","            count_0+=1\n","        loss_classification+=(predLabel-trueLabel)**2\n","mcrmse = ((loss.detach().numpy()/len(validation))**0.5 + (loss_classification/len(validation))**0.5)/2\n","print(mcrmse)\n","print(prediction/len(validation)) #validation_size"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-22T21:42:37.220787Z","iopub.status.busy":"2022-11-22T21:42:37.219783Z","iopub.status.idle":"2022-11-22T21:42:37.229034Z","shell.execute_reply":"2022-11-22T21:42:37.227851Z","shell.execute_reply.started":"2022-11-22T21:42:37.220745Z"},"trusted":true},"outputs":[],"source":["count_0, count_1, loss_classification"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":4583788,"sourceId":42292,"sourceType":"competition"}],"dockerImageVersionId":30302,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
